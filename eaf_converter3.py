# Jupyter Labç”¨ EAFãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›ã‚³ãƒ¼ãƒ‰ï¼ˆå®Œå…¨ç‰ˆï¼šIPAâ†’tipaå¤‰æ›ã€morphæ•´åˆ—ã€æ–‡åˆ†å‰²å¯¾å¿œã€éŸ³å£°åˆ‡ã‚Šå‡ºã—æ©Ÿèƒ½ä»˜ãï¼‰
import xml.etree.ElementTree as ET
import os
import re
import shutil
import zipfile
from pathlib import Path
from typing import Dict, List, Optional

# ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
AUDIO_LIBRARY = None
try:
    import librosa
    import soundfile as sf
    AUDIO_LIBRARY = 'librosa'
    print("âœ… librosa + soundfile ã‚’ä½¿ç”¨ã—ã¾ã™")
except ImportError:
    try:
        from pydub import AudioSegment
        AUDIO_LIBRARY = 'pydub'
        print("âœ… pydub ã‚’ä½¿ç”¨ã—ã¾ã™")
    except ImportError:
        try:
            import wave
            import numpy as np
            AUDIO_LIBRARY = 'wave'
            print("âœ… æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª wave ã‚’ä½¿ç”¨ã—ã¾ã™ï¼ˆWAVãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å¯¾å¿œï¼‰")
        except ImportError:
            AUDIO_LIBRARY = None
            print("âš ï¸ éŸ³å£°å‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãªã—ï¼ˆãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›ã®ã¿åˆ©ç”¨å¯èƒ½ï¼‰")

def get_desktop_path():
    """ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã®ãƒ‘ã‚¹ã‚’å–å¾—ï¼ˆOSåˆ¥å¯¾å¿œï¼‰"""
    import platform
    
    system = platform.system()
    
    if system == "Windows":
        desktop = os.path.join(os.path.expanduser("~"), "Desktop")
        if not os.path.exists(desktop):
            desktop = os.path.join(os.path.expanduser("~"), "ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—")
    elif system == "Darwin":
        desktop = os.path.join(os.path.expanduser("~"), "Desktop")
    else:
        desktop = os.path.join(os.path.expanduser("~"), "Desktop")
        if not os.path.exists(desktop):
            desktop = os.path.expanduser("~")
    
    return desktop

class EAFConverter:
    def __init__(self, eaf_file_path: str, wav_file_path: str = None):
        self.eaf_file_path = eaf_file_path
        self.wav_file_path = wav_file_path
        self.tree = None
        self.root = None
        self.time_slots = {}
        self.tiers = {}
        
        # éŸ³å£°å‡¦ç†ç”¨ã®å±æ€§
        self.audio_data = None
        self.sample_rate = None
        self.audio_available = False
        
    def load_audio(self):
        """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        if not self.wav_file_path:
            print("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›ã®ã¿å®Ÿè¡Œã—ã¾ã™ã€‚")
            return False
            
        if not os.path.exists(self.wav_file_path):
            print(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.wav_file_path}")
            return False
            
        if AUDIO_LIBRARY is None:
            print("ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚éŸ³å£°åˆ†å‰²æ©Ÿèƒ½ã¯ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚")
            return False
            
        try:
            if AUDIO_LIBRARY == 'librosa':
                self.audio_data, self.sample_rate = librosa.load(self.wav_file_path, sr=None)
                print(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {self.wav_file_path}")
                print(f"ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å‘¨æ³¢æ•°: {self.sample_rate}Hz, é•·ã•: {len(self.audio_data)/self.sample_rate:.2f}ç§’")
                
            elif AUDIO_LIBRARY == 'pydub':
                if self.wav_file_path.lower().endswith('.wav'):
                    self.audio_data = AudioSegment.from_wav(self.wav_file_path)
                elif self.wav_file_path.lower().endswith('.mp3'):
                    self.audio_data = AudioSegment.from_mp3(self.wav_file_path)
                else:
                    self.audio_data = AudioSegment.from_file(self.wav_file_path)
                self.sample_rate = self.audio_data.frame_rate
                print(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {self.wav_file_path}")
                print(f"ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å‘¨æ³¢æ•°: {self.sample_rate}Hz, é•·ã•: {len(self.audio_data)/1000:.2f}ç§’")
                
            elif AUDIO_LIBRARY == 'wave':
                with wave.open(self.wav_file_path, 'rb') as wav_file:
                    self.sample_rate = wav_file.getframerate()
                    frames = wav_file.readframes(wav_file.getnframes())
                    self.audio_data = np.frombuffer(frames, dtype=np.int16)
                print(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {self.wav_file_path}")
                print(f"ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å‘¨æ³¢æ•°: {self.sample_rate}Hz, é•·ã•: {len(self.audio_data)/self.sample_rate:.2f}ç§’")
                
            self.audio_available = True
            return True
            
        except Exception as e:
            print(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False
        
    def parse_eaf(self):
        """EAFãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã™ã‚‹"""
        try:
            self.tree = ET.parse(self.eaf_file_path)
            self.root = self.tree.getroot()
            print(f"EAFãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ­£å¸¸ã«èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {self.eaf_file_path}")
        except ET.ParseError as e:
            print(f"XMLãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
            return False
        except FileNotFoundError:
            print(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.eaf_file_path}")
            return False
            
        # ã‚¿ã‚¤ãƒ ã‚¹ãƒ­ãƒƒãƒˆã‚’å–å¾—
        time_order = self.root.find('TIME_ORDER')
        if time_order is not None:
            for time_slot in time_order.findall('TIME_SLOT'):
                slot_id = time_slot.get('TIME_SLOT_ID')
                time_value = time_slot.get('TIME_VALUE')
                self.time_slots[slot_id] = int(time_value) if time_value else 0
        
        print(f"ã‚¿ã‚¤ãƒ ã‚¹ãƒ­ãƒƒãƒˆæ•°: {len(self.time_slots)}")
        
        # ãƒ†ã‚£ã‚¢æƒ…å ±ã‚’è¡¨ç¤º
        print("\nåˆ©ç”¨å¯èƒ½ãªãƒ†ã‚£ã‚¢:")
        for tier in self.root.findall('TIER'):
            tier_id = tier.get('TIER_ID')
            print(f"  - {tier_id}")
            
        # ãƒ†ã‚£ã‚¢ã‚’å–å¾—ï¼ˆALIGNABLE_ANNOTATIONã¨REF_ANNOTATIONä¸¡æ–¹ã‚’ãƒã‚§ãƒƒã‚¯ï¼‰
        for tier in self.root.findall('TIER'):
            tier_id = tier.get('TIER_ID')
            self.tiers[tier_id] = []
            
            # ALIGNABLE_ANNOTATIONã‚’ãƒã‚§ãƒƒã‚¯
            for annotation in tier.findall('.//ALIGNABLE_ANNOTATION'):
                start_id = annotation.get('TIME_SLOT_REF1')
                end_id = annotation.get('TIME_SLOT_REF2')
                value_elem = annotation.find('ANNOTATION_VALUE')
                value = value_elem.text if value_elem is not None else ""
                
                self.tiers[tier_id].append({
                    'start_time': self.time_slots.get(start_id, 0),
                    'end_time': self.time_slots.get(end_id, 0),
                    'value': value.strip() if value else "",
                    'type': 'ALIGNABLE'
                })
            
            # REF_ANNOTATIONã‚‚ãƒã‚§ãƒƒã‚¯
            for annotation in tier.findall('.//REF_ANNOTATION'):
                ref_id = annotation.get('ANNOTATION_REF')
                value_elem = annotation.find('ANNOTATION_VALUE')
                value = value_elem.text if value_elem is not None else ""
                
                # å‚ç…§å…ˆã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®æ™‚é–“ã‚’å–å¾—
                ref_start, ref_end = self._get_ref_time(ref_id)
                
                self.tiers[tier_id].append({
                    'start_time': ref_start,
                    'end_time': ref_end,
                    'value': value.strip() if value else "",
                    'type': 'REF',
                    'ref_id': ref_id
                })
            
            # é–‹å§‹æ™‚é–“ã§ã‚½ãƒ¼ãƒˆ
            self.tiers[tier_id].sort(key=lambda x: x['start_time'])
            print(f"  {tier_id}: {len(self.tiers[tier_id])} ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³")
        
        return True
    
    def _get_ref_time(self, ref_id: str) -> tuple:
        """REF_ANNOTATIONã®å‚ç…§å…ˆã®æ™‚é–“ã‚’å–å¾—"""
        # ã™ã¹ã¦ã®ãƒ†ã‚£ã‚¢ã‚’æ¤œç´¢ã—ã¦å‚ç…§å…ˆã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¦‹ã¤ã‘ã‚‹
        for tier in self.root.findall('TIER'):
            for annotation in tier.findall('.//ALIGNABLE_ANNOTATION'):
                if annotation.get('ANNOTATION_ID') == ref_id:
                    start_id = annotation.get('TIME_SLOT_REF1')
                    end_id = annotation.get('TIME_SLOT_REF2')
                    return (self.time_slots.get(start_id, 0), self.time_slots.get(end_id, 0))
            
            # REF_ANNOTATIONãŒä»–ã®REF_ANNOTATIONã‚’å‚ç…§ã—ã¦ã„ã‚‹å ´åˆ
            for annotation in tier.findall('.//REF_ANNOTATION'):
                if annotation.get('ANNOTATION_ID') == ref_id:
                    nested_ref_id = annotation.get('ANNOTATION_REF')
                    if nested_ref_id:
                        return self._get_ref_time(nested_ref_id)
        
        return (0, 0)
    
    def _split_sentences_by_punctuation(self, text: str, morph: str, gloss: str, translation: str, start_time: int = 0, end_time: int = 0) -> List[Dict]:
        """æ–‡æœ«è¨˜å·ï¼ˆ.ã€?ã€!ï¼‰ã§æ–‡ã‚’åˆ†å‰²ã—ã€æ™‚é–“æƒ…å ±ã‚‚ä¿æŒ"""
        # æ–‡æœ«è¨˜å·ã‚’æ¤œå‡ºã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³
        sentence_pattern = r'([.?!]+)'
        
        # textå±¤ã‚’æ–‡æœ«è¨˜å·ã§åˆ†å‰²
        text_parts = re.split(sentence_pattern, text)
        
        sentences = []
        current_text = ""
        
        # morphå±¤ã¨glosså±¤ã‚’ã‚¹ãƒšãƒ¼ã‚¹ã§åˆ†å‰²
        morph_words = morph.split() if morph else []
        gloss_words = gloss.split() if gloss else []
        
        morph_idx = 0
        gloss_idx = 0
        
        # æ™‚é–“è¨ˆç®—ç”¨
        total_chars = len(text.replace('.', '').replace('?', '').replace('!', ''))
        current_chars = 0
        
        for part in text_parts:
            # æ–‡æœ«è¨˜å·ã‹ã©ã†ã‹ãƒã‚§ãƒƒã‚¯
            is_punctuation = bool(re.match(r'^[.?!]+$', part))
            
            if is_punctuation:
                # æ–‡æœ«è¨˜å·ã®å ´åˆ
                current_text += part
                
                # ç¾åœ¨ã®æ–‡ã‚’å®Œæˆã•ã›ã‚‹
                if current_text.strip():
                    # ã“ã®æ–‡ã«å¯¾å¿œã™ã‚‹morphæ•°ã‚’è¨ˆç®—
                    clean_text = current_text.replace('.', '').replace('?', '').replace('!', '')
                    text_words = clean_text.split()
                    num_morphs = 0
                    for word in text_words:
                        # =ã‚„-ã§åˆ†å‰²ã•ã‚ŒãŸå½¢æ…‹ç´ æ•°ã‚’æ•°ãˆã‚‹
                        morphs_in_word = len(re.split(r'[=-]', word))
                        num_morphs += morphs_in_word
                    
                    # å¯¾å¿œã™ã‚‹morphã¨glossã‚’å–å¾—
                    sent_morphs = morph_words[morph_idx:morph_idx + num_morphs] if morph_idx < len(morph_words) else []
                    sent_glosses = gloss_words[gloss_idx:gloss_idx + num_morphs] if gloss_idx < len(gloss_words) else []
                    
                    # æ™‚é–“ã®æ¨å®šè¨ˆç®—
                    sentence_chars = len(clean_text)
                    if total_chars > 0 and start_time != end_time:
                        char_ratio = sentence_chars / total_chars
                        duration = end_time - start_time
                        sentence_start = start_time + int((current_chars / total_chars) * duration)
                        sentence_end = sentence_start + int(char_ratio * duration)
                    else:
                        sentence_start = start_time
                        sentence_end = end_time
                    
                    sentences.append({
                        'text': current_text.strip(),
                        'morph': ' '.join(sent_morphs),
                        'gloss': ' '.join(sent_glosses),
                        'translation': translation,  # ç¿»è¨³ã¯å…¨ä½“ã§å…±æœ‰
                        'start_time': sentence_start,
                        'end_time': sentence_end
                    })
                    
                    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ›´æ–°
                    morph_idx += num_morphs
                    gloss_idx += num_morphs
                    current_chars += sentence_chars
                    current_text = ""
            
            elif part.strip():
                # é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆã®å ´åˆ
                current_text += part
        
        # æ®‹ã‚Šã®ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹å ´åˆ
        if current_text.strip():
            # æ®‹ã‚Šã®morphã¨glossã‚’ä½¿ç”¨
            remaining_morphs = morph_words[morph_idx:] if morph_idx < len(morph_words) else []
            remaining_glosses = gloss_words[gloss_idx:] if gloss_idx < len(gloss_words) else []
            
            # æ®‹ã‚Šã®æ™‚é–“è¨ˆç®—
            sentence_chars = len(current_text.replace('.', '').replace('?', '').replace('!', ''))
            if total_chars > 0 and start_time != end_time:
                char_ratio = sentence_chars / total_chars
                duration = end_time - start_time
                sentence_start = start_time + int((current_chars / total_chars) * duration)
                sentence_end = sentence_start + int(char_ratio * duration)
            else:
                sentence_start = start_time
                sentence_end = end_time
            
            sentences.append({
                'text': current_text.strip(),
                'morph': ' '.join(remaining_morphs),
                'gloss': ' '.join(remaining_glosses),
                'translation': translation,
                'start_time': sentence_start,
                'end_time': sentence_end
            })
        
        return sentences if sentences else [{
            'text': text, 
            'morph': morph, 
            'gloss': gloss, 
            'translation': translation,
            'start_time': start_time,
            'end_time': end_time
        }]
    
    def extract_sentences(self, tier_names: Dict[str, str] = None) -> List[Dict]:
        """æ–‡ã”ã¨ã«text, morph, gloss, translation, æ™‚é–“æƒ…å ±ã‚’æŠ½å‡º"""
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ†ã‚£ã‚¢åï¼ˆå®Ÿéš›ã®ãƒ†ã‚£ã‚¢åã«åˆã‚ã›ã¦ä¿®æ­£ï¼‰
        if tier_names is None:
            tier_names = {
                'text': 'text@KS',
                'morph': 'morph@KS', 
                'gloss': 'gloss@KS',
                'translation': 'translation@KS'  # @TSã«ä¿®æ­£
            }
        
        sentences = []
        
        # å„ãƒ†ã‚£ã‚¢ã‹ã‚‰å¯¾å¿œã™ã‚‹åŒºé–“ã‚’è¦‹ã¤ã‘ã‚‹
        text_tier = self.tiers.get(tier_names['text'], [])
        morph_tier = self.tiers.get(tier_names['morph'], [])
        gloss_tier = self.tiers.get(tier_names['gloss'], [])
        translation_tier = self.tiers.get(tier_names['translation'], [])
        
        print(f"\næŠ½å‡ºå¯¾è±¡:")
        print(f"  text: {len(text_tier)} é …ç›®")
        print(f"  morph: {len(morph_tier)} é …ç›®")
        print(f"  gloss: {len(gloss_tier)} é …ç›®")
        print(f"  translation: {len(translation_tier)} é …ç›®")
        
        for i, text_annotation in enumerate(text_tier):
            if not text_annotation['value']:
                continue
                
            start_time = text_annotation['start_time']
            end_time = text_annotation['end_time']
            
            # å¯¾å¿œã™ã‚‹morph, gloss, translationã‚’è¦‹ã¤ã‘ã‚‹
            morph = self._find_overlapping_annotation(morph_tier, start_time, end_time)
            gloss = self._find_overlapping_annotation(gloss_tier, start_time, end_time)
            translation = self._find_overlapping_annotation(translation_tier, start_time, end_time)
            
            # æ–‡æœ«è¨˜å·ã§åˆ†å‰²ï¼ˆæ™‚é–“æƒ…å ±ä»˜ãï¼‰
            split_sentences = self._split_sentences_by_punctuation(
                text_annotation['value'], morph, gloss, translation, start_time, end_time
            )
            
            sentences.extend(split_sentences)
        
        print(f"\næŠ½å‡ºã•ã‚ŒãŸæ–‡æ•°: {len(sentences)}")
        return sentences
    
    def _find_overlapping_annotation(self, tier_data: List[Dict], start_time: int, end_time: int) -> str:
        """æŒ‡å®šã•ã‚ŒãŸæ™‚é–“ç¯„å›²ã¨é‡è¤‡ã™ã‚‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¦‹ã¤ã‘ã¦çµåˆ"""
        matching_annotations = []
        
        for annotation in tier_data:
            # æ™‚é–“ç¯„å›²ãŒé‡è¤‡ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            overlap_start = max(annotation['start_time'], start_time)
            overlap_end = min(annotation['end_time'], end_time)
            
            if overlap_start < overlap_end or (annotation['start_time'] == start_time and annotation['end_time'] == end_time):
                # é‡è¤‡ãŒã‚ã‚‹ã€ã¾ãŸã¯å®Œå…¨ä¸€è‡´ã®å ´åˆ
                matching_annotations.append(annotation)
        
        # é‡è¤‡ã™ã‚‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ™‚é–“é †ã«ã‚½ãƒ¼ãƒˆã—ã¦çµåˆ
        matching_annotations.sort(key=lambda x: x['start_time'])
        return ' '.join([ann['value'] for ann in matching_annotations if ann['value']])
    
    def save_audio_segment(self, start_ms: int, end_ms: int, output_path: str, padding_ms: int = 100):
        """æŒ‡å®šã•ã‚ŒãŸæ™‚é–“ç¯„å›²ã®éŸ³å£°ã‚’ä¿å­˜"""
        if not self.audio_available:
            return False
            
        try:
            # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚’è¿½åŠ ï¼ˆå‰å¾Œã«å°‘ã—ä½™è£•ã‚’æŒãŸã›ã‚‹ï¼‰
            padded_start = max(0, start_ms - padding_ms)
            
            if AUDIO_LIBRARY == 'librosa':
                # ãƒŸãƒªç§’ã‚’ã‚µãƒ³ãƒ—ãƒ«æ•°ã«å¤‰æ›
                start_sample = int((padded_start / 1000.0) * self.sample_rate)
                end_sample = int((end_ms / 1000.0) * self.sample_rate)
                padded_end_sample = min(len(self.audio_data), end_sample + int((padding_ms / 1000.0) * self.sample_rate))
                
                # éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’åˆ‡ã‚Šå‡ºã—
                audio_segment = self.audio_data[start_sample:padded_end_sample]
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                sf.write(output_path, audio_segment, self.sample_rate)
                
            elif AUDIO_LIBRARY == 'pydub':
                padded_end = end_ms + padding_ms
                
                # éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’åˆ‡ã‚Šå‡ºã—
                audio_segment = self.audio_data[padded_start:padded_end]
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                audio_segment.export(output_path, format="wav")
                
            elif AUDIO_LIBRARY == 'wave':
                # ãƒŸãƒªç§’ã‚’ã‚µãƒ³ãƒ—ãƒ«æ•°ã«å¤‰æ›
                start_sample = int((padded_start / 1000.0) * self.sample_rate)
                end_sample = int((end_ms / 1000.0) * self.sample_rate)
                padded_end_sample = min(len(self.audio_data), end_sample + int((padding_ms / 1000.0) * self.sample_rate))
                
                # éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’åˆ‡ã‚Šå‡ºã—
                audio_segment = self.audio_data[start_sample:padded_end_sample]
                
                # WAVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
                with wave.open(output_path, 'wb') as wav_out:
                    wav_out.setnchannels(1)  # ãƒ¢ãƒãƒ©ãƒ«
                    wav_out.setsampwidth(2)  # 16bit
                    wav_out.setframerate(self.sample_rate)
                    wav_out.writeframes(audio_segment.tobytes())
            
            return True
            
        except Exception as e:
            print(f"éŸ³å£°ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def split_audio_to_desktop(self, sentences: List[Dict], folder_name: str = None, 
                              padding_ms: int = 100, create_zip: bool = False):
        """åˆ†å‰²ã•ã‚ŒãŸæ–‡ã®éŸ³å£°ã‚’ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã«ä¿å­˜ï¼ˆãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚‚å«ã‚€ï¼‰"""
        if not self.audio_available:
            print("éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚éŸ³å£°åˆ†å‰²ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚")
            return None
            
        # ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ãƒ‘ã‚¹ã‚’å–å¾—
        desktop_path = get_desktop_path()
        print(f"ğŸ“ ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ãƒ‘ã‚¹: {desktop_path}")
        
        # å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€åã‚’æ±ºå®š
        if not folder_name:
            base_name = Path(self.eaf_file_path).stem
            folder_name = f"{base_name}_sentences"
        
        # ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã«å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        output_path = Path(desktop_path) / folder_name
        if output_path.exists():
            # æ—¢å­˜ãƒ•ã‚©ãƒ«ãƒ€ãŒã‚ã‚‹å ´åˆã¯ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            import time
            timestamp = int(time.time())
            backup_path = Path(desktop_path) / f"{folder_name}_backup_{timestamp}"
            shutil.move(str(output_path), str(backup_path))
            print(f"ğŸ“¦ æ—¢å­˜ãƒ•ã‚©ãƒ«ãƒ€ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {backup_path}")
        
        output_path.mkdir(parents=True, exist_ok=True)
        
        if not sentences:
            print("åˆ†å‰²ã™ã‚‹æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return None
        
        saved_files = []
        
        # å„æ–‡ã«å¯¾ã—ã¦éŸ³å£°ã‚’åˆ‡ã‚Šå‡ºã—
        for i, sentence in enumerate(sentences, 1):
            if not sentence.get('start_time') or not sentence.get('end_time'):
                print(f"âš ï¸ æ–‡ {i} ã«æ™‚é–“æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                continue
                
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆï¼ˆç•ªå·ä»˜ãï¼‰
            safe_text = re.sub(r'[^\w\s-]', '', sentence['text'][:30])  # å®‰å…¨ãªãƒ•ã‚¡ã‚¤ãƒ«å
            safe_text = re.sub(r'\s+', '_', safe_text.strip())
            filename = f"{i:03d}_{safe_text}.wav"
            output_file = output_path / filename
            
            # éŸ³å£°ã‚’ä¿å­˜
            success = self.save_audio_segment(
                sentence['start_time'], 
                sentence['end_time'], 
                str(output_file),
                padding_ms
            )
            
            if success:
                saved_files.append({
                    'number': i,
                    'text': sentence['text'],
                    'start_time': sentence['start_time'],
                    'end_time': sentence['end_time'],
                    'duration': sentence['end_time'] - sentence['start_time'],
                    'file_path': str(output_file)
                })
                print(f"âœ… ä¿å­˜å®Œäº†: {filename} ({sentence['start_time']}ms - {sentence['end_time']}ms)")
            else:
                print(f"âŒ ä¿å­˜å¤±æ•—: {filename}")
        
        # GB4Eå½¢å¼ã®TeXãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        print("ğŸ“ GB4Eå½¢å¼ã®TeXãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆä¸­...")
        gb4e_content = self.to_gb4e_format(sentences)
        gb4e_file = output_path / 'sentences_gb4e.tex'
        with open(gb4e_file, 'w', encoding='utf-8', newline='\n') as f:
            f.write(gb4e_content)
        print(f"âœ… GB4Eå½¢å¼ä¿å­˜: {gb4e_file.name}")
        
        # DOCå½¢å¼ã®TXTãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        print("ğŸ“„ DOCå½¢å¼ã®TXTãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆä¸­...")
        doc_content = self.to_doc_format(sentences)
        doc_file = output_path / 'sentences_doc.txt'
        with open(doc_file, 'w', encoding='utf-8') as f:
            f.write(doc_content)
        print(f"âœ… DOCå½¢å¼ä¿å­˜: {doc_file.name}")
        
        # çµæœã‚’ã¾ã¨ã‚ãŸãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        summary_file = output_path / 'audio_summary.txt'
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«åˆ†å‰²çµæœ\n")
            f.write("="*50 + "\n\n")
            f.write(f"å…ƒãƒ•ã‚¡ã‚¤ãƒ«: {self.eaf_file_path}\n")
            f.write(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«: {self.wav_file_path}\n")
            f.write(f"ç·æ–‡æ•°: {len(saved_files)}\n")
            f.write(f"ä¿å­˜å ´æ‰€: {output_path}\n\n")
            f.write("ğŸ“ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«:\n")
            f.write(f"  - GB4Eå½¢å¼: {gb4e_file.name}\n")
            f.write(f"  - DOCå½¢å¼: {doc_file.name}\n")
            f.write(f"  - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«: {len(saved_files)}å€‹\n\n")
            
            for file_info in saved_files:
                f.write(f"{file_info['number']:03d}. {file_info['text']}\n")
                f.write(f"     æ™‚é–“: {file_info['start_time']}ms - {file_info['end_time']}ms "
                       f"(é•·ã•: {file_info['duration']}ms)\n")
                f.write(f"     ãƒ•ã‚¡ã‚¤ãƒ«: {Path(file_info['file_path']).name}\n\n")
        
        # READMEãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        readme_file = output_path / 'README.txt'
        with open(readme_file, 'w', encoding='utf-8') as f:
            f.write("EAFãƒ•ã‚¡ã‚¤ãƒ«éŸ³å£°åˆ†å‰²çµæœ\n")
            f.write("="*30 + "\n\n")
            f.write("ğŸ“ ã“ã®ãƒ•ã‚©ãƒ«ãƒ€ã«ã¯ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒå«ã¾ã‚Œã¦ã„ã¾ã™:\n\n")
            f.write("ğŸµ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«:\n")
            f.write(f"  - {len(saved_files)}å€‹ã®åˆ†å‰²ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ« (001_*.wav ï½ {len(saved_files):03d}_*.wav)\n")
            f.write("  - å„ãƒ•ã‚¡ã‚¤ãƒ«ã¯æ–‡å˜ä½ã§åˆ†å‰²ã•ã‚Œã¦ã„ã¾ã™\n\n")
            f.write("ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«:\n")
            f.write(f"  - {gb4e_file.name}: LaTeXç”¨gb4eå½¢å¼ã®ä¾‹æ–‡é›†\n")
            f.write(f"  - {doc_file.name}: ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã®ä¾‹æ–‡é›†\n")
            f.write(f"  - {summary_file.name}: è©³ç´°ãªåˆ†å‰²æƒ…å ±\n")
            f.write(f"  - {readme_file.name}: ã“ã®èª¬æ˜ãƒ•ã‚¡ã‚¤ãƒ«\n\n")
            f.write("ğŸ’¡ ä½¿ç”¨æ–¹æ³•:\n")
            f.write("  - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«: å„æ–‡ã®éŸ³å£°ã‚’å€‹åˆ¥ã«å†ç”Ÿå¯èƒ½\n")
            f.write("  - GB4Eãƒ•ã‚¡ã‚¤ãƒ«: LaTeXã§ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã—ã¦è¨€èªå­¦è«–æ–‡ç”¨ã®ä¾‹æ–‡é›†ã‚’ä½œæˆ\n")
            f.write("  - DOCãƒ•ã‚¡ã‚¤ãƒ«: ãã®ã¾ã¾æ–‡æ›¸ã«è²¼ã‚Šä»˜ã‘å¯èƒ½\n\n")
            f.write(f"ğŸ“… ä½œæˆæ—¥æ™‚: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"ğŸ”§ å…ƒãƒ•ã‚¡ã‚¤ãƒ«: {Path(self.eaf_file_path).name}\n")
        
        # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹å ´åˆ
        zip_file_path = None
        if create_zip and saved_files:
            zip_file_path = Path(desktop_path) / f"{folder_name}.zip"
            try:
                with zipfile.ZipFile(zip_file_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                    for file_path in output_path.rglob('*'):
                        if file_path.is_file():
                            arcname = file_path.relative_to(output_path)
                            zipf.write(file_path, arcname)
                
                print(f"ğŸ“¦ ZIPãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå®Œäº†: {zip_file_path}")
            except Exception as e:
                print(f"âŒ ZIPä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
                zip_file_path = None
        
        if saved_files:
            print(f"\nğŸ‰ éŸ³å£°åˆ†å‰²å®Œäº†!")
            print(f"ğŸµ ä¿å­˜ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(saved_files)}")
            print(f"ğŸ“ GB4Eå½¢å¼ãƒ•ã‚¡ã‚¤ãƒ«: {gb4e_file.name}")
            print(f"ğŸ“„ DOCå½¢å¼ãƒ•ã‚¡ã‚¤ãƒ«: {doc_file.name}")
            print(f"ğŸ“ ä¿å­˜å ´æ‰€: {output_path}")
            print(f"ğŸ“‹ è©³ç´°æƒ…å ±: {summary_file.name}")
            print(f"ğŸ’¡ ä½¿ã„æ–¹: {readme_file.name}")
            if zip_file_path:
                print(f"ğŸ“¦ ZIPãƒ•ã‚¡ã‚¤ãƒ«: {zip_file_path}")
        
        return {
            'saved_files': saved_files,
            'output_path': str(output_path),
            'gb4e_file': str(gb4e_file),
            'doc_file': str(doc_file),
            'summary_file': str(summary_file),
            'readme_file': str(readme_file),
            'zip_file': str(zip_file_path) if zip_file_path else None,
            'total_files': len(saved_files)
        }
    
    def _convert_ipa_to_tipa(self, text: str) -> str:
        """IPAæ–‡å­—ã‚’tipaãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®å½¢å¼ã«å¤‰æ›"""
        if not text:
            return text
            
        # IPAæ–‡å­—ã¨tipaã‚³ãƒãƒ³ãƒ‰ã®å¯¾å¿œè¡¨ï¼ˆ{}ã‚’è¿½åŠ ã—ã¦åŒºåˆ‡ã‚Šã‚’æ˜ç¢ºåŒ–ï¼‰
        ipa_to_tipa = {
            'É¨': '\\textbari{}',
            'É¯': '\\textturnm{}',
            'É›': '\\textepsilon{}',
            'É”': '\\textopeno{}',
            'Ã¦': '\\textae{}',
            'É‘': '\\textscripta{}',
            'É’': '\\textturnscripta{}',
            'É™': '\\textschwa{}',
            'Éª': '\\textsci{}',
            'ÊŠ': '\\textupsilon{}',
            'Êƒ': '\\textesh{}',
            'Ê’': '\\textyogh{}',
            'Î¸': '\\texttheta{}',
            'Ã°': '\\texteth{}',
            'Å‹': '\\texteng{}',
            'É²': '\\textltailn{}',
            'É³': '\\textrtailn{}',
            'É±': '\\textltailm{}',
            'É¾': '\\textfishhookr{}',
            'É½': '\\textrtailr{}',
            'É»': '\\textturnr{}',
            'É­': '\\textrtaill{}',
            'Ê': '\\textturny{}',
            'Êˆ': '\\textrtailt{}',
            'É–': '\\textrtaild{}',
            'Ê‚': '\\textrtails{}',
            'Ê': '\\textrtailz{}',
            'É•': '\\textctc{}',
            'Ê‘': '\\textctj{}',
            'Ã§': '\\textccedilla{}',
            'Ê': '\\textctj{}',
            'É£': '\\textgamma{}',
            'Ï‡': '\\textchi{}',
            'Ê': '\\textinvscr{}',
            'Ä§': '\\textcrh{}',
            'Ê•': '\\textrevglotstop{}',
            'Ê”': '\\textglotstop{}',
            'É¸': '\\textphi{}',
            'Î²': '\\textbeta{}',
            'Ê‹': '\\textscriptv{}',
            'É¹': '\\textturnr{}',
            'É°': '\\textturnmrleg{}',
            'Éº': '\\textlhti{}',
            'É¢': '\\textscg{}',
            'Ê›': '\\texthtg{}',
            'Ê„': '\\texthtbardotlessjdotlessj{}',
            'É ': '\\texthtg{}',
            'É¡': '\\textscg{}',
            'Ë': '\\textlengthmark{}',
            'Ëˆ': '\\textprimstress{}',
            'ËŒ': '\\textsecstress{}',
            'Ê²': '\\textpal{}',
            'Ê·': '\\textlab{}',
            'Ê°': '\\textsuperscript{h}',
            'â¿': '\\textsuperscript{n}',
            'Ê¼': '\\textglotstop{}',
        }
        
        result = text
        for ipa_char, tipa_command in ipa_to_tipa.items():
            result = result.replace(ipa_char, tipa_command)
        
        return result
    
    def _align_morphs_with_text(self, text: str, morph: str) -> str:
        """textå±¤ã®åŒºåˆ‡ã‚Šæ–‡å­—ï¼ˆ=ã‚„-ï¼‰ã«åŸºã¥ã„ã¦morphå±¤ã‚’å†é…ç½®"""
        if not text or not morph:
            return morph
        
        # morphå±¤ã‚’ã‚¹ãƒšãƒ¼ã‚¹ã§åˆ†å‰²
        morph_list = morph.split()
        if not morph_list:
            return morph
        
        # textå±¤ã‚’å˜èªã«åˆ†å‰²
        text_words = text.split()
        result_parts = []
        morph_idx = 0
        
        for word in text_words:
            # å˜èªå†…ã®å½¢æ…‹ç´ å¢ƒç•Œã‚’è¦‹ã¤ã‘ã‚‹ï¼ˆ=, -ï¼‰
            # å½¢æ…‹ç´ å¢ƒç•Œã§åˆ†å‰²ï¼ˆåŒºåˆ‡ã‚Šæ–‡å­—ã‚‚ä¿æŒï¼‰
            segments = re.split(r'([=-])', word)
            word_morphs = []
            
            for segment in segments:
                if segment in ['=', '-']:
                    # åŒºåˆ‡ã‚Šæ–‡å­—ã¯ãã®ã¾ã¾ä¿æŒ
                    continue
                elif segment.strip():  # ç©ºã§ãªã„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ
                    if morph_idx < len(morph_list):
                        word_morphs.append(morph_list[morph_idx])
                        morph_idx += 1
            
            # å˜èªå†…ã®å½¢æ…‹ç´ ã‚’åŒºåˆ‡ã‚Šæ–‡å­—ã§çµåˆ
            if word_morphs:
                # å…ƒã®å˜èªã®åŒºåˆ‡ã‚Šæ–‡å­—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å¾©å…ƒ
                morphs_with_delims = []
                morph_pos = 0
                
                for segment in segments:
                    if segment in ['=', '-']:
                        morphs_with_delims.append(segment)
                    elif segment.strip() and morph_pos < len(word_morphs):
                        morphs_with_delims.append(word_morphs[morph_pos])
                        morph_pos += 1
                
                result_parts.append(''.join(morphs_with_delims))
        
        return ' '.join(result_parts)
    
    def _align_words_for_doc(self, text_line: str, gloss_line: str) -> tuple:
        """docå½¢å¼ç”¨ã«å˜èªã®é–‹å§‹ä½ç½®ã‚’æƒãˆã‚‹"""
        if not text_line or not gloss_line:
            return text_line, gloss_line
        
        text_words = text_line.split()
        gloss_words = gloss_line.split()
        
        # ã‚ˆã‚Šæ­£ç¢ºãªæ–‡å­—å¹…è¨ˆç®—
        def char_width(s):
            import unicodedata
            width = 0
            for char in s:
                # Unicodeæ–‡å­—ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’ä½¿ç”¨ã—ã¦ã‚ˆã‚Šæ­£ç¢ºã«åˆ¤å®š
                if unicodedata.east_asian_width(char) in ('F', 'W'):
                    # å…¨è§’æ–‡å­—ï¼ˆFull width, Wideï¼‰
                    width += 2
                elif unicodedata.east_asian_width(char) in ('H', 'Na', 'N'):
                    # åŠè§’æ–‡å­—ï¼ˆHalf width, Narrow, Neutralï¼‰
                    width += 1
                else:
                    # ãã®ä»–ï¼ˆA=Ambiguousï¼‰ã¯ç’°å¢ƒä¾å­˜ã ãŒã€ã“ã“ã§ã¯1ã¨ã—ã¦æ‰±ã†
                    width += 1
            return width
        
        # å˜èªæ•°ãŒç•°ãªã‚‹å ´åˆã¯çŸ­ã„æ–¹ã«åˆã‚ã›ã‚‹
        min_len = min(len(text_words), len(gloss_words))
        if len(text_words) != len(gloss_words):
            print(f"è­¦å‘Š: å˜èªæ•°ãŒä¸€è‡´ã—ã¾ã›ã‚“ (text: {len(text_words)}, gloss: {len(gloss_words)})")
        
        aligned_text_parts = []
        aligned_gloss_parts = []
        
        for i in range(min_len):
            text_word = text_words[i]
            gloss_word = gloss_words[i]
            
            text_width = char_width(text_word)
            gloss_width = char_width(gloss_word)
            
            # ä¸¡æ–¹ã®å˜èªã®æœ€å¤§å¹…ã‚’è¨ˆç®—ï¼ˆæœ€ä½2æ–‡å­—ã®ã‚¹ãƒšãƒ¼ã‚¹ã‚’ç¢ºä¿ï¼‰
            max_width = max(text_width, gloss_width) + 2
            
            # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚’è¿½åŠ 
            text_padding = max_width - text_width
            gloss_padding = max_width - gloss_width
            
            if i < min_len - 1:  # æœ€å¾Œã®å˜èªã§ãªã„å ´åˆ
                aligned_text_parts.append(text_word + ' ' * text_padding)
                aligned_gloss_parts.append(gloss_word + ' ' * gloss_padding)
            else:  # æœ€å¾Œã®å˜èª
                aligned_text_parts.append(text_word)
                aligned_gloss_parts.append(gloss_word)
        
        # ä½™ã£ãŸå˜èªãŒã‚ã‚‹å ´åˆã®å‡¦ç†
        if len(text_words) > min_len:
            remaining_text = ' '.join(text_words[min_len:])
            aligned_text_parts.append(' ' + remaining_text)
        
        if len(gloss_words) > min_len:
            remaining_gloss = ' '.join(gloss_words[min_len:])
            aligned_gloss_parts.append(' ' + remaining_gloss)
        
        return ''.join(aligned_text_parts), ''.join(aligned_gloss_parts)
    
    def to_gb4e_format(self, sentences: List[Dict]) -> str:
        """gb4eå½¢å¼ã«å¤‰æ›ï¼ˆ3æ®µã‚°ãƒ­ã‚¹ï¼štext, gloss, translationï¼‰"""
        output = []
        
        # LaTeXç”¨ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¿½åŠ 
        output.append("% UTF-8ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ç”¨è¨­å®š")
        output.append("% \\usepackage[utf8]{inputenc}")
        output.append("% \\usepackage{CJKutf8}")
        output.append("% \\usepackage{gb4e}")
        output.append("% \\usepackage{tipa}")
        output.append("")
        
        for i, sentence in enumerate(sentences, 1):
            if not sentence['text']:
                continue
                
            output.append("\\begin{exe}")
            output.append("\\ex")
            
            # 1æ®µç›®: textï¼ˆIPAã‚’tipaã«å¤‰æ›ï¼‰
            text_tipa = self._convert_ipa_to_tipa(sentence['text'])
            output.append(f"\\gll {text_tipa}\\\\")
            
            # 2æ®µç›®: glossï¼ˆåŒºåˆ‡ã‚Šæ–‡å­—ã«åŸºã¥ãæ•´åˆ—ï¼‰
            if sentence['gloss']:
                # glosså±¤ã‚’textå±¤ã®åŒºåˆ‡ã‚Šæ–‡å­—ã«åŸºã¥ã„ã¦å†é…ç½®
                aligned_gloss = self._align_morphs_with_text(sentence['text'], sentence['gloss'])
                output.append(f"     {aligned_gloss}\\\\")
            else:
                output.append("     \\\\")
            
            # 3æ®µç›®: translation
            if sentence['translation']:
                output.append(f"\\glt {sentence['translation']}")
            else:
                output.append("\\glt")
            
            output.append("\\end{exe}")
            output.append("")
        
        return "\n".join(output)
    
    def _convert_tipa_back_to_ipa(self, text: str) -> str:
        """tipaã‚³ãƒãƒ³ãƒ‰ã‚’å…ƒã®IPAæ–‡å­—ã«æˆ»ã™"""
        if not text:
            return text
            
        result = text
        result = result.replace('\\textbari{}', 'É¨')
        result = result.replace('\\textturnm{}', 'É¯')
        result = result.replace('\\textepsilon{}', 'É›')
        result = result.replace('\\textopeno{}', 'É”')
        result = result.replace('\\textae{}', 'Ã¦')
        result = result.replace('\\textscripta{}', 'É‘')
        result = result.replace('\\textturnscripta{}', 'É’')
        result = result.replace('\\textschwa{}', 'É™')
        result = result.replace('\\textsci{}', 'Éª')
        result = result.replace('\\textupsilon{}', 'ÊŠ')
        result = result.replace('\\textesh{}', 'Êƒ')
        result = result.replace('\\textyogh{}', 'Ê’')
        result = result.replace('\\texttheta{}', 'Î¸')
        result = result.replace('\\texteth{}', 'Ã°')
        result = result.replace('\\texteng{}', 'Å‹')
        result = result.replace('\\textltailn{}', 'É²')
        result = result.replace('\\textrtailn{}', 'É³')
        result = result.replace('\\textltailm{}', 'É±')
        result = result.replace('\\textfishhookr{}', 'É¾')
        result = result.replace('\\textrtailr{}', 'É½')
        result = result.replace('\\textturnr{}', 'É»')
        result = result.replace('\\textrtaill{}', 'É­')
        result = result.replace('\\textturny{}', 'Ê')
        result = result.replace('\\textrtailt{}', 'Êˆ')
        result = result.replace('\\textrtaild{}', 'É–')
        result = result.replace('\\textrtails{}', 'Ê‚')
        result = result.replace('\\textrtailz{}', 'Ê')
        result = result.replace('\\textctc{}', 'É•')
        result = result.replace('\\textctj{}', 'Ê‘')
        result = result.replace('\\textccedilla{}', 'Ã§')
        result = result.replace('\\textgamma{}', 'É£')
        result = result.replace('\\textchi{}', 'Ï‡')
        result = result.replace('\\textinvscr{}', 'Ê')
        result = result.replace('\\textcrh{}', 'Ä§')
        result = result.replace('\\textrevglotstop{}', 'Ê•')
        result = result.replace('\\textglotstop{}', 'Ê”')
        result = result.replace('\\textphi{}', 'É¸')
        result = result.replace('\\textbeta{}', 'Î²')
        result = result.replace('\\textscriptv{}', 'Ê‹')
        result = result.replace('\\textturnmrleg{}', 'É°')
        result = result.replace('\\textlhti{}', 'Éº')
        result = result.replace('\\textscg{}', 'É¢')
        result = result.replace('\\texthtg{}', 'Ê›')
        result = result.replace('\\texthtbardotlessjdotlessj{}', 'Ê„')
        result = result.replace('\\textbardotlessj{}', 'ÉŸ')
        result = result.replace('\\textlengthmark{}', 'Ë')
        result = result.replace('\\textprimstress{}', 'Ëˆ')
        result = result.replace('\\textsecstress{}', 'ËŒ')
        result = result.replace('\\textpal{}', 'Ê²')
        result = result.replace('\\textlab{}', 'Ê·')
        result = result.replace('\\textsuperscript{h}', 'Ê°')
        result = result.replace('\\textsuperscript{n}', 'â¿')
        
        return result
    
    def to_doc_format(self, sentences: List[Dict], debug: bool = False) -> str:
        """docå½¢å¼ï¼ˆgb4eå½¢å¼ã‚’ãƒ™ãƒ¼ã‚¹ã«ã‚³ãƒãƒ³ãƒ‰é¡ã‚’é™¤å»ã€IPAæ–‡å­—ã‚’å¾©å…ƒã€ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆèª¿æ•´ï¼‰"""
        output = []
        
        for i, sentence in enumerate(sentences, 1):
            if not sentence['text']:
                continue
                
            # ä¾‹æ–‡ç•ªå·
            output.append(f"({i})")
            
            # 1æ®µç›®: textï¼ˆIPAã‚’tipaã«å¤‰æ›ã—ã¦ã‹ã‚‰å…ƒã«æˆ»ã™ï¼‰
            text_tipa = self._convert_ipa_to_tipa(sentence['text'])
            text_original = self._convert_tipa_back_to_ipa(text_tipa)
            
            # 2æ®µç›®: glossï¼ˆåŒºåˆ‡ã‚Šæ–‡å­—ã«åŸºã¥ãæ•´åˆ—ï¼‰
            if sentence['gloss']:
                # glosså±¤ã‚’textå±¤ã®åŒºåˆ‡ã‚Šæ–‡å­—ã«åŸºã¥ã„ã¦å†é…ç½®
                aligned_gloss = self._align_morphs_with_text(sentence['text'], sentence['gloss'])
                
                if debug:
                    print(f"\n--- ä¾‹æ–‡ {i} ã®ãƒ‡ãƒãƒƒã‚°æƒ…å ± ---")
                    print(f"å…ƒã®text: '{sentence['text']}'")
                    print(f"å…ƒã®gloss: '{sentence['gloss']}'")
                    print(f"æ•´åˆ—å¾Œgloss: '{aligned_gloss}'")
                    print(f"æœ€çµ‚text: '{text_original}'")
                
                # å˜èªã®é–‹å§‹ä½ç½®ã‚’æƒãˆã‚‹
                aligned_text, aligned_gloss_final = self._align_words_for_doc(text_original, aligned_gloss)
                
                if debug:
                    print(f"ä½ç½®èª¿æ•´å¾Œtext: '{aligned_text}'")
                    print(f"ä½ç½®èª¿æ•´å¾Œgloss: '{aligned_gloss_final}'")
                    print(f"textå˜èªæ•°: {len(text_original.split())}")
                    print(f"glosså˜èªæ•°: {len(aligned_gloss.split())}")
                
                output.append(aligned_text)
                output.append(aligned_gloss_final)
            else:
                output.append(text_original)
                output.append("")
            
            # 3æ®µç›®: translationï¼ˆã‚·ãƒ³ã‚°ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã‚‚é™¤å»ï¼‰
            if sentence['translation']:
                output.append(sentence['translation'])
            else:
                output.append("")
            
            output.append("")
        
        return "\n".join(output)

# è¨ºæ–­é–¢æ•°
def diagnose_eaf_file(eaf_filename, wav_filename=None):
    """EAFãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹é€ ã‚’è©³ã—ãèª¿ã¹ã‚‹"""
    converter = EAFConverter(eaf_filename, wav_filename)
    if not converter.parse_eaf():
        return
    
    if wav_filename:
        print("\néŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚§ãƒƒã‚¯...")
        converter.load_audio()
    
    print("\n=== è©³ç´°ãªãƒ†ã‚£ã‚¢æƒ…å ± ===")
    for tier_name, annotations in converter.tiers.items():
        print(f"\nãƒ†ã‚£ã‚¢: {tier_name}")
        print(f"  ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æ•°: {len(annotations)}")
        
        # æœ€åˆã®3ã¤ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡¨ç¤º
        for i, ann in enumerate(annotations[:3]):
            ann_type = ann.get('type', 'UNKNOWN')
            print(f"  [{i+1}] ({ann_type}) æ™‚é–“: {ann['start_time']}-{ann['end_time']}")
            content = ann['value'][:100] + '...' if len(ann['value']) > 100 else ann['value']
            print(f"      å†…å®¹: '{content}'")
        
        if len(annotations) > 3:
            print(f"  ... (ä»– {len(annotations)-3} å€‹)")

# ä½¿ç”¨ä¾‹
def convert_eaf_file(eaf_filename, wav_filename=None, tier_names=None, output_format='both', 
                    debug=False, save_audio=True, audio_folder_name=None, 
                    audio_padding_ms=100, create_zip=False):
    """
    EAFãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¤‰æ›ã™ã‚‹é–¢æ•°ï¼ˆéŸ³å£°åˆ‡ã‚Šå‡ºã—æ©Ÿèƒ½ä»˜ãï¼‰
    
    Args:
        eaf_filename: EAFãƒ•ã‚¡ã‚¤ãƒ«å
        wav_filename: WAVãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆéŸ³å£°åˆ‡ã‚Šå‡ºã—ç”¨ã€ä»»æ„ï¼‰
        tier_names: ãƒ†ã‚£ã‚¢åã®è¾æ›¸ {'text': 'å®Ÿéš›ã®ãƒ†ã‚£ã‚¢å', ...}
        output_format: 'gb4e', 'doc', 'both'
        debug: ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹ã‹ã©ã†ã‹
        save_audio: éŸ³å£°åˆ†å‰²ã‚’å®Ÿè¡Œã™ã‚‹ã‹ã©ã†ã‹
        audio_folder_name: éŸ³å£°ä¿å­˜ç”¨ãƒ•ã‚©ãƒ«ãƒ€å
        audio_padding_ms: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰å¾Œãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆãƒŸãƒªç§’ï¼‰
        create_zip: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ZIPã‚’ä½œæˆã™ã‚‹ã‹ã©ã†ã‹
    
    Returns:
        å¤‰æ›çµæœã®è¾æ›¸
    """
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    if not os.path.exists(eaf_filename):
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {eaf_filename}")
        print("\nç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ•ã‚¡ã‚¤ãƒ«:")
        for file in os.listdir('.'):
            if file.endswith('.eaf'):
                print(f"  {file}")
        return None
    
    if wav_filename and not os.path.exists(wav_filename):
        print(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {wav_filename}")
        print("ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›ã®ã¿å®Ÿè¡Œã—ã¾ã™ã€‚")
        wav_filename = None
    
    # å¤‰æ›å®Ÿè¡Œ
    converter = EAFConverter(eaf_filename, wav_filename)
    
    if not converter.parse_eaf():
        return None
    
    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã¯èª­ã¿è¾¼ã¿
    if wav_filename:
        print("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        converter.load_audio()
    
    sentences = converter.extract_sentences(tier_names)
    
    if not sentences:
        print("å¤‰æ›å¯èƒ½ãªæ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return None
    
    result = {
        'sentences': sentences,
        'eaf_file': eaf_filename,
        'wav_file': wav_filename,
        'gb4e_file': None,
        'doc_file': None,
        'audio_result': None
    }
    
    # ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›çµæœã‚’è¡¨ç¤ºãƒ»ä¿å­˜
    print("\n" + "="*70)
    
    if output_format in ['gb4e', 'both']:
        print("GB4Eå½¢å¼:")
        print("-" * 40)
        gb4e_content = converter.to_gb4e_format(sentences)
        print(gb4e_content)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆUTF-8 BOMãªã—ï¼‰
        gb4e_filename = f"{eaf_filename}_gb4e.tex"
        with open(gb4e_filename, 'w', encoding='utf-8', newline='\n') as f:
            f.write(gb4e_content)
        print(f"\nâœ… GB4Eå½¢å¼ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {gb4e_filename}")
        result['gb4e_file'] = gb4e_filename
    
    if output_format in ['both']:
        print("\n" + "="*70)
    
    if output_format in ['doc', 'both']:
        print("DOCå½¢å¼:")
        print("-" * 40)
        doc_content = converter.to_doc_format(sentences, debug=debug)
        print(doc_content)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        doc_filename = f"{eaf_filename}_doc.txt"
        with open(doc_filename, 'w', encoding='utf-8') as f:
            f.write(doc_content)
        print(f"\nâœ… DOCå½¢å¼ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {doc_filename}")
        result['doc_file'] = doc_filename
    
    # éŸ³å£°åˆ†å‰²ã‚’å®Ÿè¡Œ
    if save_audio and wav_filename and converter.audio_available:
        print("\n" + "="*70)
        print("ğŸµ éŸ³å£°åˆ†å‰²ã‚’å®Ÿè¡Œä¸­...")
        audio_result = converter.split_audio_to_desktop(
            sentences, audio_folder_name, audio_padding_ms, create_zip
        )
        result['audio_result'] = audio_result
    elif save_audio and wav_filename:
        print("\néŸ³å£°åˆ†å‰²: ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸ")
    elif save_audio:
        print("\néŸ³å£°åˆ†å‰²: WAVãƒ•ã‚¡ã‚¤ãƒ«ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸ")
    
    print(f"\nğŸ‰ å¤‰æ›å®Œäº†!")
    print(f"ğŸ“Š æŠ½å‡ºã•ã‚ŒãŸæ–‡æ•°: {len(sentences)}")
    if result['gb4e_file']:
        print(f"ğŸ“ GB4Eå½¢å¼: {result['gb4e_file']}")
    if result['doc_file']:
        print(f"ğŸ“„ DOCå½¢å¼: {result['doc_file']}")
    if result['audio_result']:
        print(f"ğŸµ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«: {result['audio_result']['total_files']}å€‹")
        print(f"ğŸ“ éŸ³å£°ä¿å­˜å ´æ‰€: {result['audio_result']['output_path']}")
    
    return result

# å®Ÿè¡Œæ–¹æ³•ã®èª¬æ˜
print("=== EAFãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›ãƒ„ãƒ¼ãƒ«ï¼ˆä¿®æ­£ç‰ˆãƒ»éŸ³å£°åˆ‡ã‚Šå‡ºã—æ©Ÿèƒ½ä»˜ãï¼‰ ===")
print("æ©Ÿèƒ½:")
print("- IPAæ–‡å­—ã‚’è‡ªå‹•çš„ã«tipaã‚³ãƒãƒ³ãƒ‰ã«å¤‰æ›")
print("- glosså±¤ã‚’textå±¤ã®åŒºåˆ‡ã‚Šæ–‡å­—ï¼ˆ=, -ï¼‰ã«åŸºã¥ã„ã¦æ•´åˆ—")
print("- æ–‡æœ«è¨˜å·ï¼ˆ., ?, !ï¼‰ã§ã®è‡ªå‹•æ–‡åˆ†å‰²")
print("- gb4eå½¢å¼ï¼šLaTeXç”¨ã®å®Œå…¨ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ")
print("- docå½¢å¼ï¼šgb4eå½¢å¼ã‚’ãƒ™ãƒ¼ã‚¹ã«ã‚³ãƒãƒ³ãƒ‰é¡ã‚’é™¤å»ã—ãŸãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆèª¿æ•´ä»˜ãï¼‰")
print("- éŸ³å£°åˆ†å‰²ï¼šæ–‡å˜ä½ã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†å‰²ã—ã¦ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã«ä¿å­˜")
print("- ZIPãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆï¼šéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã¾ã¨ã‚ã¦ZIPåœ§ç¸®")
print()

if AUDIO_LIBRARY:
    print("ä½¿ç”¨æ–¹æ³•:")
    print("1. ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›ã®ã¿:")
    print("   result = convert_eaf_file('your_file.eaf')")
    print()
    print("2. ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›ï¼‹éŸ³å£°åˆ†å‰²:")
    print("   result = convert_eaf_file('your_file.eaf', 'your_file.wav')")
    print()
    print("3. å®Œå…¨ã‚«ã‚¹ã‚¿ãƒ :")
    print("   result = convert_eaf_file('your_file.eaf', 'your_file.wav',")
    print("                            output_format='both',")
    print("                            save_audio=True,")
    print("                            audio_folder_name='My_Audio_Project',")
    print("                            create_zip=True)")
    print()
    print("4. ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰:")
    print("   result = convert_eaf_file('your_file.eaf', debug=True)")
    print()
    print("5. è¨ºæ–­å®Ÿè¡Œ:")
    print("   diagnose_eaf_file('your_file.eaf', 'your_file.wav')")
else:
    print("éŸ³å£°å‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›ã®ã¿åˆ©ç”¨å¯èƒ½ã§ã™ã€‚")
    print("éŸ³å£°åˆ†å‰²æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ä»¥ä¸‹ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
    print("  pip install librosa soundfile  # æ¨å¥¨")
    print("  pip install pydub              # è»½é‡ç‰ˆ")
    print()
    print("ä½¿ç”¨æ–¹æ³•ï¼ˆãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›ã®ã¿ï¼‰:")
    print("1. åŸºæœ¬çš„ãªå¤‰æ›:")
    print("   result = convert_eaf_file('your_file.eaf')")
    print()
    print("2. ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰:")
    print("   result = convert_eaf_file('your_file.eaf', debug=True)")
    print()
    print("3. è¨ºæ–­å®Ÿè¡Œ:")
    print("   diagnose_eaf_file('your_file.eaf')")